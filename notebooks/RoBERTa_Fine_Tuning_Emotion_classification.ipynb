{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoBERTa_Fine_Tuning_Emotion_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f974fd93f0548879967ad9fe26a7995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_595e5f50bdb14e00835027cfd6dccadf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a7336b4a47e4f2f80ea1e6e11b49c3a",
              "IPY_MODEL_791559c84a8f43b69f9cffecf07c82ec",
              "IPY_MODEL_c3a06e98ceb545f8ad955726dd5fedb5"
            ]
          }
        },
        "595e5f50bdb14e00835027cfd6dccadf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4a7336b4a47e4f2f80ea1e6e11b49c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eafce52682004ac88f1ba5720547e30a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cf48fbb01404856870e44d259480ba2"
          }
        },
        "791559c84a8f43b69f9cffecf07c82ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d85cde11b72c47fcbd4b0f981ebd7509",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1dcb65c8229f4c68b91d92cd11ab69ee"
          }
        },
        "c3a06e98ceb545f8ad955726dd5fedb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05849f652a2744b888d8e0fb0766b130",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdff77833c7e40a694ca7eed04f6742b"
          }
        },
        "eafce52682004ac88f1ba5720547e30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cf48fbb01404856870e44d259480ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d85cde11b72c47fcbd4b0f981ebd7509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1dcb65c8229f4c68b91d92cd11ab69ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05849f652a2744b888d8e0fb0766b130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdff77833c7e40a694ca7eed04f6742b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62db80574db247bdbb2bb349bfbd4313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb0876485bd14222bd59438a02d480ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aaed7774dcd94b79b7fd67504b2407fe",
              "IPY_MODEL_297c91a785fe4627a510819f11993a3b",
              "IPY_MODEL_76dedd8c338a48eeb57177356c4b39be"
            ]
          }
        },
        "cb0876485bd14222bd59438a02d480ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "aaed7774dcd94b79b7fd67504b2407fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_433e95fb096d4cf18cb33119ca65739e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8dde433a7293480ba25760099224740c"
          }
        },
        "297c91a785fe4627a510819f11993a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4888f700b50d4668bcfde24fc863c850",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 563,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 563,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d0a46794481436fb3ff8447a99c4c73"
          }
        },
        "76dedd8c338a48eeb57177356c4b39be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f73ebf79e064c72a155437db7376180",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 563/563 [02:55&lt;00:00,  3.21it/s, loss=0.192, v_num=1]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4240775062764e1981a1ac7ebc16fd92"
          }
        },
        "433e95fb096d4cf18cb33119ca65739e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8dde433a7293480ba25760099224740c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4888f700b50d4668bcfde24fc863c850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d0a46794481436fb3ff8447a99c4c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f73ebf79e064c72a155437db7376180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4240775062764e1981a1ac7ebc16fd92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f315c9bcdab41cc8d2607ce61dc24d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_366f8596c92c4c7f81b3945e0ea4dc8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b28a5eaeef9c4f4bbbcbc091328c0454",
              "IPY_MODEL_9f912b99c72140b0bc4c24367cc4ccc4",
              "IPY_MODEL_d289240c3e124718a7e2c481b553a167"
            ]
          }
        },
        "366f8596c92c4c7f81b3945e0ea4dc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b28a5eaeef9c4f4bbbcbc091328c0454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a834799c634344b59538b594ed22179a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78b85a16bc6c441083c3d223c5eb1a29"
          }
        },
        "9f912b99c72140b0bc4c24367cc4ccc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d55d5eb488d0408f95ec741ed6d3b896",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 63,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 63,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5e408da51574829add47a99cbceba65"
          }
        },
        "d289240c3e124718a7e2c481b553a167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f5843b51ef644efaa6d86d6cec2af5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 63/63 [00:06&lt;00:00,  9.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_420c8b69731d4e309f0547a3e92758f1"
          }
        },
        "a834799c634344b59538b594ed22179a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78b85a16bc6c441083c3d223c5eb1a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d55d5eb488d0408f95ec741ed6d3b896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5e408da51574829add47a99cbceba65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f5843b51ef644efaa6d86d6cec2af5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "420c8b69731d4e309f0547a3e92758f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielstumpp/sentiment-analysis/blob/main/notebooks/RoBERTa_Fine_Tuning_Emotion_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj6eoKzotv5I"
      },
      "source": [
        "## Emotion Classification using Fine-tuned BERT model\n",
        "\n",
        "In this tutorial, I will show to fine-tune a language model (LM) for emotion classification with code adapted from this [tutorial](https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/) by MARCIN ZABŁOCKI. I adapted his tutorial and modified the code to suit the emotion classification task using a different BERT model. Please refer to his tutorial for more detailed explanations for each code block. I really liked his tutorial because of the attention to detail and the use of high-level libraries to take care of certain parts of the model such as training and finding a good learning rate. \n",
        "\n",
        "Before you get started, make sure to enable `GPU` in the runtime and be sure to \n",
        "restart the runtime in this environment after installing the `pytorch-lr-finder` library.\n",
        "\n",
        "This tutorial is in a rough draft so if you find any issues with this tutorial or have any further questions reach out to me via [Twitter](https://twitter.com/omarsar0).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2tokZqttmTA"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers tokenizers pytorch-lightning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ZKIIGvuW5m"
      },
      "source": [
        "## Note need to Restart runtime after running this code segment\n",
        "%%capture\n",
        "!git clone https://github.com/davidtvs/pytorch-lr-finder.git && cd pytorch-lr-finder && python setup.py install"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqRRWe4UuuIh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3876508d-5c96-463f-b445-9b01994f4afe"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from typing import List\n",
        "import torch.nn.functional as F\n",
        "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import logging\n",
        "import os\n",
        "from functools import lru_cache\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "from argparse import Namespace\n",
        "from sklearn.metrics import classification_report\n",
        "torch.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_whSBDujRiga"
      },
      "source": [
        "## Load the Pretrained Language Model\n",
        "We are first going to look at pretrained language model provided by HuggingFace models. We will use a variant of BERT, called DistilRoBERTa base. The `base` model has less parameters than the `larger` model. \n",
        "\n",
        "[RoBERTa](https://arxiv.org/abs/1907.11692) is a variant of of BERT which \"*modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates*\".\n",
        "\n",
        "Knowledge distillation help to train smaller LMs with similar performance and potential."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvHNcMckSR4M"
      },
      "source": [
        "First, let's load the tokenizer for this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPbTd5lmuzQn"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KAbKMqJSWRo"
      },
      "source": [
        "Now let's load the actual model with the LM head that takes care of the prediciton for the LM. When fine-tuning we don't use the head and instead use the base model. The code below shows how to do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCXYlMydzQlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6ea350-5ba9-48b9-9308-f00f34d9f93b"
      },
      "source": [
        "model = AutoModelWithLMHead.from_pretrained(\"distilroberta-base\")\n",
        "base_model = model.base_model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2_8S8BXSpNa"
      },
      "source": [
        "Let's now try out the tokenizer first:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fidSmH-zrY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af60b273-16e4-420c-f3e6-2166c89b5460"
      },
      "source": [
        "text = \"Elvis is the king of rock!\"\n",
        "enc = tokenizer.encode_plus(text)\n",
        "enc.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8F8yQCDTDQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d407f19-5185-4740-f4c6-0986b41fd388"
      },
      "source": [
        "print(enc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 9682, 9578, 16, 5, 8453, 9, 3152, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3wSCLKW0ndh"
      },
      "source": [
        "`input_ids` are the numerical encoding of the tokens in the vocabulary. `attention_mask` is an addition option used when batching sequences together and you want to tell the model which tokens should be attented to ([read more](https://huggingface.co/transformers/glossary.html#attention-mask)). The attention mask information helps when dealing with variance in the size of sequences and we need a way to tell the model that we don't want to attend to the padded indices of the sequence.\n",
        "\n",
        "We are only using `input_ids` and `attention_mask`\n",
        "\n",
        "We need to also unsqueeze to simulate batch processing\n",
        "\n",
        "Using DistilBertForSequenceClassification: https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxsts4uT0PgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc378909-1a6b-4785-87ae-3982fe0e167d"
      },
      "source": [
        "out = base_model(torch.tensor(enc[\"input_ids\"]).unsqueeze(0), torch.tensor(enc[\"attention_mask\"]).unsqueeze(0))\n",
        "out[0].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiCO-n_1AHIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b9c209-6e95-45db-c286-c97cee5ac701"
      },
      "source": [
        "## size of representation of one of the tokens \n",
        "out[0][:,0,:].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srwIb9nr4g4t"
      },
      "source": [
        "`torch.Size([1, 768])` represents batch_size, number of tokens in input text (lenght of tokenized text), model's output hidden size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAsg0H6g53Bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fe7b57-efd6-427e-cee5-f7d17e1aa032"
      },
      "source": [
        "t = \"Elvis is the king of rock\"\n",
        "enc = tokenizer.encode_plus(t)\n",
        "token_representations = base_model(torch.tensor(enc[\"input_ids\"]).unsqueeze(0))[0][0]\n",
        "print(enc[\"input_ids\"])\n",
        "print(tokenizer.decode(enc[\"input_ids\"]))\n",
        "print(f\"Length: {len(enc['input_ids'])}\")\n",
        "print(token_representations.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 9682, 9578, 16, 5, 8453, 9, 3152, 2]\n",
            "<s>Elvis is the king of rock</s>\n",
            "Length: 9\n",
            "torch.Size([9, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RFifOoY7Hsc"
      },
      "source": [
        "## Building Custom Classification head on top of LM base model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSUMm4Oq7nvR"
      },
      "source": [
        "Use Mish activiation function as in the one proposed in the original tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCEDXLxq628O"
      },
      "source": [
        "# from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py\n",
        "@torch.jit.script\n",
        "def mish(input):\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "  \n",
        "class Mish(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return mish(input)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6Ln6KWm74ku"
      },
      "source": [
        "The model we will use to do the fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VDRSRsc71H2"
      },
      "source": [
        "class EmoModel(nn.Module):\n",
        "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, base_model_output_size),\n",
        "            Mish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(base_model_output_size, n_classes)\n",
        "        )\n",
        "        \n",
        "        for layer in self.classifier:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
        "                if layer.bias is not None:\n",
        "                    layer.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input_, *args):\n",
        "        X, attention_mask = input_\n",
        "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
        "        \n",
        "        # maybe do some pooling / RNNs... go crazy here!\n",
        "        \n",
        "        # use the <s> representation\n",
        "        return self.classifier(hidden_states[0][:, 0, :])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjgME-3O8Yfo"
      },
      "source": [
        "### Pretest the model with dummy text\n",
        "We want to ensure that the model is returing the right information back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6H9eF8A8XeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59bf2c4a-f1b7-4d5d-8490-f1a3d435a234"
      },
      "source": [
        "classifier = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, 3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sjfHJ_L9iNH"
      },
      "source": [
        "X = torch.tensor(enc[\"input_ids\"]).unsqueeze(0).to('cpu')\n",
        "attn = torch.tensor(enc[\"attention_mask\"]).unsqueeze(0).to('cpu')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6QhCuEC-y2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fef206-4f90-4207-83ac-d23bd6cae33b"
      },
      "source": [
        "classifier((X, attn))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2935,  0.0254, -0.0722]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-N7WSY7Cb7v"
      },
      "source": [
        "## Prepare your dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDWkjaLV-5tj"
      },
      "source": [
        "!mkdir -p tokenizer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMMm5Ye1Db-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922bd0e9-904c-495e-fef2-f3cbf2f31a76"
      },
      "source": [
        "## load pretrained tokenizer information\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.json',\n",
              " 'tokenizer/merges.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FVtbmrzDkF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82554ea-9b45-4a6a-a1c7-0f101d9ba40e"
      },
      "source": [
        "!ls tokenizer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merges.txt\t\t tokenizer_config.json\tvocab.json\n",
            "special_tokens_map.json  tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhTEgIaLEDRo"
      },
      "source": [
        "Implement CollateFN using fast tokenizers.\n",
        "This function basically takes care of proper tokenization and batches of sequences. This way you don't need to create your batches manually. Find out more about Tokenizers [here](https://github.com/huggingface/tokenizers/tree/master/bindings/python)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCLBZsMDn4s"
      },
      "source": [
        "class TokenizersCollateFn:\n",
        "    def __init__(self, max_tokens=512):\n",
        "\n",
        "        ## RoBERTa uses BPE tokenizer similar to GPT\n",
        "        t = ByteLevelBPETokenizer(\n",
        "            \"tokenizer/vocab.json\",\n",
        "            \"tokenizer/merges.txt\"\n",
        "        )\n",
        "        t._tokenizer.post_processor = BertProcessing(\n",
        "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
        "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
        "        )\n",
        "        t.enable_truncation(max_tokens)\n",
        "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
        "        #t.enable_padding(max_length=max_tokens, pad_id=t.token_to_id(\"<pad>\"))\n",
        "        self.tokenizer = t\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
        "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
        "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
        "        labels = torch.tensor([x[1] for x in batch])\n",
        "        \n",
        "        return (sequences_padded, attention_masks_padded), labels"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hu70Ng0Eqls"
      },
      "source": [
        "## Getting the Data and Preview it\n",
        "Below we are going to load the data and show you how to create the splits. However, we don't need to split the data manually becuase I have already created the splits and stored those files seperately which you can quickly download below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3SoJH3fUsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57971510-1f9d-4d1e-f554-47e1bf6ca41a"
      },
      "source": [
        "!wget https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
        "!wget https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
        "!wget https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-05 04:41:08--  https://www.dropbox.com/s/ikkqxfdbdec3fuj/test.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ikkqxfdbdec3fuj/test.txt [following]\n",
            "--2021-11-05 04:41:08--  https://www.dropbox.com/s/raw/ikkqxfdbdec3fuj/test.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uceff443dd46e5df4140e1408209.dl.dropboxusercontent.com/cd/0/inline/BZVjxFkPnq3Kq9E9EMJcXVeh1tQRUQTi3G_hBAmyD8qi1348M7Vf6VnqF05PwU5p6yiplCSJWM4ZiFq4Clqfva4tG-emjjO-8caj0nsCZ6Cab8AlV4PCiBInRleEMb5U2WAE-eB4UwUvkyOBYugB15qz/file# [following]\n",
            "--2021-11-05 04:41:09--  https://uceff443dd46e5df4140e1408209.dl.dropboxusercontent.com/cd/0/inline/BZVjxFkPnq3Kq9E9EMJcXVeh1tQRUQTi3G_hBAmyD8qi1348M7Vf6VnqF05PwU5p6yiplCSJWM4ZiFq4Clqfva4tG-emjjO-8caj0nsCZ6Cab8AlV4PCiBInRleEMb5U2WAE-eB4UwUvkyOBYugB15qz/file\n",
            "Resolving uceff443dd46e5df4140e1408209.dl.dropboxusercontent.com (uceff443dd46e5df4140e1408209.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uceff443dd46e5df4140e1408209.dl.dropboxusercontent.com (uceff443dd46e5df4140e1408209.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206760 (202K) [text/plain]\n",
            "Saving to: ‘test.txt.1’\n",
            "\n",
            "test.txt.1          100%[===================>] 201.91K  1.26MB/s    in 0.2s    \n",
            "\n",
            "2021-11-05 04:41:10 (1.26 MB/s) - ‘test.txt.1’ saved [206760/206760]\n",
            "\n",
            "--2021-11-05 04:41:10--  https://www.dropbox.com/s/1pzkadrvffbqw6o/train.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/1pzkadrvffbqw6o/train.txt [following]\n",
            "--2021-11-05 04:41:10--  https://www.dropbox.com/s/raw/1pzkadrvffbqw6o/train.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc806a21948f4bd3ee5d4be6e575.dl.dropboxusercontent.com/cd/0/inline/BZUfGXmYqwKaTIKIiJSDZtzTUJG7XiuAbXzGVyhmT-Ls4nvy4-em8KCMC1UwGtHHJ7G38xcmxymuapC2i6QdvaSOHngy6CLw_8B0lv7yNPM4Yvt2GnTZ7ZRZR2rFYGqHwGxacxZ64dtDW57lggAx89p2/file# [following]\n",
            "--2021-11-05 04:41:11--  https://uc806a21948f4bd3ee5d4be6e575.dl.dropboxusercontent.com/cd/0/inline/BZUfGXmYqwKaTIKIiJSDZtzTUJG7XiuAbXzGVyhmT-Ls4nvy4-em8KCMC1UwGtHHJ7G38xcmxymuapC2i6QdvaSOHngy6CLw_8B0lv7yNPM4Yvt2GnTZ7ZRZR2rFYGqHwGxacxZ64dtDW57lggAx89p2/file\n",
            "Resolving uc806a21948f4bd3ee5d4be6e575.dl.dropboxusercontent.com (uc806a21948f4bd3ee5d4be6e575.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc806a21948f4bd3ee5d4be6e575.dl.dropboxusercontent.com (uc806a21948f4bd3ee5d4be6e575.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1658616 (1.6M) [text/plain]\n",
            "Saving to: ‘train.txt.1’\n",
            "\n",
            "train.txt.1         100%[===================>]   1.58M  1.84MB/s    in 0.9s    \n",
            "\n",
            "2021-11-05 04:41:12 (1.84 MB/s) - ‘train.txt.1’ saved [1658616/1658616]\n",
            "\n",
            "--2021-11-05 04:41:12--  https://www.dropbox.com/s/2mzialpsgf9k5l3/val.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/2mzialpsgf9k5l3/val.txt [following]\n",
            "--2021-11-05 04:41:13--  https://www.dropbox.com/s/raw/2mzialpsgf9k5l3/val.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf2439ac3b15b8087f0d8d636a9.dl.dropboxusercontent.com/cd/0/inline/BZWKmkVpisHlLhM3TBAa_khNOj4OIxtV50WZmNAfRVkN-6wCoNHpxOsiL0LiIF2Rx3CiKd626ZFUZnsSpgBLl_qJkYbDKpcrhgaF7UEXFsSLSm1ZooxYMgJP_cze8gipz5Ii8JWwayRekYgAYSnDYaG0/file# [following]\n",
            "--2021-11-05 04:41:13--  https://ucf2439ac3b15b8087f0d8d636a9.dl.dropboxusercontent.com/cd/0/inline/BZWKmkVpisHlLhM3TBAa_khNOj4OIxtV50WZmNAfRVkN-6wCoNHpxOsiL0LiIF2Rx3CiKd626ZFUZnsSpgBLl_qJkYbDKpcrhgaF7UEXFsSLSm1ZooxYMgJP_cze8gipz5Ii8JWwayRekYgAYSnDYaG0/file\n",
            "Resolving ucf2439ac3b15b8087f0d8d636a9.dl.dropboxusercontent.com (ucf2439ac3b15b8087f0d8d636a9.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to ucf2439ac3b15b8087f0d8d636a9.dl.dropboxusercontent.com (ucf2439ac3b15b8087f0d8d636a9.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204240 (199K) [text/plain]\n",
            "Saving to: ‘val.txt.1’\n",
            "\n",
            "val.txt.1           100%[===================>] 199.45K  1.25MB/s    in 0.2s    \n",
            "\n",
            "2021-11-05 04:41:14 (1.25 MB/s) - ‘val.txt.1’ saved [204240/204240]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_03fxufWX_G"
      },
      "source": [
        "## export the datasets as txt files\n",
        "## EXERCISE: Change this to an address\n",
        "\n",
        "train_path = \"train.txt\"\n",
        "test_path = \"test.txt\"\n",
        "val_path = \"val.txt\"\n",
        "\n",
        "## emotion labels\n",
        "label2int = {\n",
        "  \"sadness\": 0,\n",
        "  \"joy\": 1,\n",
        "  \"love\": 2,\n",
        "  \"anger\": 3,\n",
        "  \"fear\": 4,\n",
        "  \"surprise\": 5\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23zHggkEpc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8238645f-1828-4049-fe1a-b5120983529e"
      },
      "source": [
        "!wget https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-05 04:41:14--  https://www.dropbox.com/s/607ptdakxuh5i4s/merged_training.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/607ptdakxuh5i4s/merged_training.pkl [following]\n",
            "--2021-11-05 04:41:15--  https://www.dropbox.com/s/raw/607ptdakxuh5i4s/merged_training.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com/cd/0/inline/BZVvyuSeax8e6Vn4I0M_2_FFka8tEK8dbLDOIMvSi_LJhPWOWhGEe3WhSKdgeAlduLadwnVaetPiXzkPM6RTVD4sdBjHX1jVhnSeh6HKOldIhbVOFB0jV9bN7lD1yc3lGUmYJkgdudIc_JFcAI-4nhX3/file# [following]\n",
            "--2021-11-05 04:41:15--  https://uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com/cd/0/inline/BZVvyuSeax8e6Vn4I0M_2_FFka8tEK8dbLDOIMvSi_LJhPWOWhGEe3WhSKdgeAlduLadwnVaetPiXzkPM6RTVD4sdBjHX1jVhnSeh6HKOldIhbVOFB0jV9bN7lD1yc3lGUmYJkgdudIc_JFcAI-4nhX3/file\n",
            "Resolving uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com (uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com (uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BZXUMH81NYAW--zRBi2PrawuT2Xwyzqk3jDOHTSMihYAyUe9PgXqOshbPBYfmiTMv_9bCfqeAmAecFZDlwUEQ5ybBqCkG216GzPERsr8YX7NJInnrhxmTf3GFXbrL96l7EVbW5iOIC7wR2equw6OhasB-PQVdvI0lftXiR8iW8yEcW4PzMHgbigxVxqKawFXFqT2EBlio2G0MXVVaU4ldzt4OUuzoLBAUL4hPAEVHbQCoCEeAamaNruDsch3vfR4Ib9fDDOeQMKmmJCj6A0LVwtmx4xEbkeXgBhW9BBaZxyIjsa5V-zHwMd7uhNfwCmhXdY-VoVyivuAKqmeucwC44Fn6iCWqoHSmLuFjoFvrk7xQoYRx8ztwVKADGAmphGUcGc/file [following]\n",
            "--2021-11-05 04:41:16--  https://uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com/cd/0/inline2/BZXUMH81NYAW--zRBi2PrawuT2Xwyzqk3jDOHTSMihYAyUe9PgXqOshbPBYfmiTMv_9bCfqeAmAecFZDlwUEQ5ybBqCkG216GzPERsr8YX7NJInnrhxmTf3GFXbrL96l7EVbW5iOIC7wR2equw6OhasB-PQVdvI0lftXiR8iW8yEcW4PzMHgbigxVxqKawFXFqT2EBlio2G0MXVVaU4ldzt4OUuzoLBAUL4hPAEVHbQCoCEeAamaNruDsch3vfR4Ib9fDDOeQMKmmJCj6A0LVwtmx4xEbkeXgBhW9BBaZxyIjsa5V-zHwMd7uhNfwCmhXdY-VoVyivuAKqmeucwC44Fn6iCWqoHSmLuFjoFvrk7xQoYRx8ztwVKADGAmphGUcGc/file\n",
            "Reusing existing connection to uc1337fd037ea7790ec7af1cbf80.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49991846 (48M) [application/octet-stream]\n",
            "Saving to: ‘merged_training.pkl.1’\n",
            "\n",
            "merged_training.pkl 100%[===================>]  47.68M  13.0MB/s    in 4.1s    \n",
            "\n",
            "2021-11-05 04:41:21 (11.7 MB/s) - ‘merged_training.pkl.1’ saved [49991846/49991846]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQrMSUTRF06B"
      },
      "source": [
        "import pickle\n",
        "\n",
        "## helper function\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGz89mNSHaYM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "e701e577-cf4b-4997-b571-037cff7c2776"
      },
      "source": [
        "data = load_from_pickle(directory=\"merged_training.pkl\")\n",
        "\n",
        "## using a sample\n",
        "emotions = [ \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
        "data= data[data[\"emotions\"].isin(emotions)]\n",
        "\n",
        "\n",
        "data = data.sample(n=20000);\n",
        "\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f97e37b4490>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEaCAYAAAD9iIezAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZWUlEQVR4nO3df7RdZX3n8ffHRBApkKBpFiapoGZgcFTAW6CFNaNQQvghiRUojkoWjc0sB3+1nSnRqWUK2oW1IyNtpUaIBpcKKa0lBRTTqG3V8iNBBsqv5oKwSAokcmOgUH76mT/2c+UQ7s29l5x7dnKez2utu87ez37OOd8NN5+z77OfvY9sExERdXhZ2wVERETvJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIioyZuhLOlDSLR0/j0r6qKR9Ja2WtL48Ti/9JekiSYOSbpV0WMdrLSr910taNJk7FhERL6aJzNOXNAXYCBwBnA0M2b5A0lJguu1zJJ0IfAg4sfT7nO0jJO0LrAUGAAPrgLfa3tLVPYqIiFFNdHjnWOAe2/cDC4AVpX0FsLAsLwAuc+N6YJqk/YDjgdW2h0rQrwbm7/AeRETEuE2dYP8zgK+X5Zm2HyzLDwEzy/Is4IGO52wobaO1v4CkJcASgD333POtBx100ARLjIio27p1635ie8ZI28Yd+pJ2A04BPrbtNtuW1JX7OdheBiwDGBgY8Nq1a7vxshER1ZB0/2jbJjK8cwJws+2Hy/rDZdiG8riptG8E5nQ8b3ZpG609IiJ6ZCKh/26eH9oBWAUMz8BZBFzV0X5mmcVzJLC1DANdB8yTNL3M9JlX2iIiokfGNbwjaU/gOOC/dTRfAKyUtBi4Hzi9tF9LM3NnEHgCOAvA9pCk84GbSr/zbA/t8B5ERMS4TWjKZq9lTD8iYuIkrbM9MNK2XJEbEVGRhH5EREUS+hERFUnoR0RUZKJX5O4S9l96TU/f774LTurp+0VEvFQ50o+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqMi4Ql/SNElXSrpL0p2SfkXSvpJWS1pfHqeXvpJ0kaRBSbdKOqzjdRaV/uslLZqsnYqIiJGN90j/c8C3bB8EvAW4E1gKrLE9F1hT1gFOAOaWnyXAxQCS9gXOBY4ADgfOHf6giIiI3hgz9CXtA/xn4FIA20/b/imwAFhRuq0AFpblBcBlblwPTJO0H3A8sNr2kO0twGpgflf3JiIitms8R/oHAJuBL0n6kaRLJO0JzLT9YOnzEDCzLM8CHuh4/obSNlr7C0haImmtpLWbN2+e2N5ERMR2jSf0pwKHARfbPhR4nOeHcgCwbcDdKMj2MtsDtgdmzJjRjZeMiIhiPKG/Adhg+4ayfiXNh8DDZdiG8ripbN8IzOl4/uzSNlp7RET0yJihb/sh4AFJB5amY4E7gFXA8AycRcBVZXkVcGaZxXMksLUMA10HzJM0vZzAnVfaIiKiR6aOs9+HgK9K2g24FziL5gNjpaTFwP3A6aXvtcCJwCDwROmL7SFJ5wM3lX7n2R7qyl5ERMS4jCv0bd8CDIyw6dgR+ho4e5TXWQ4sn0iB8WL7L72mp+933wUn9fT9ImLy5IrciIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIioyrtCXdJ+k2yTdImltadtX0mpJ68vj9NIuSRdJGpR0q6TDOl5nUem/XtKiydmliIgYzUSO9N9u+xDbA2V9KbDG9lxgTVkHOAGYW36WABdD8yEBnAscARwOnDv8QREREb2xI8M7C4AVZXkFsLCj/TI3rgemSdoPOB5YbXvI9hZgNTB/B94/IiImaLyhb+DbktZJWlLaZtp+sCw/BMwsy7OABzqeu6G0jdb+ApKWSForae3mzZvHWV5ERIzH1HH2O9r2Rkm/CKyWdFfnRtuW5G4UZHsZsAxgYGCgK68ZERGNcR3p295YHjcB36AZk3+4DNtQHjeV7huBOR1Pn13aRmuPiIgeGTP0Je0paa/hZWAe8M/AKmB4Bs4i4KqyvAo4s8ziORLYWoaBrgPmSZpeTuDOK20REdEj4xnemQl8Q9Jw/6/Z/pakm4CVkhYD9wOnl/7XAicCg8ATwFkAtocknQ/cVPqdZ3uoa3sSERFjGjP0bd8LvGWE9keAY0doN3D2KK+1HFg+8TIjIqIbckVuRERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERUZd+hLmiLpR5KuLusHSLpB0qCkKyTtVtp3L+uDZfv+Ha/xsdJ+t6Tju70zERGxfRM50v8IcGfH+qeBC22/AdgCLC7ti4Etpf3C0g9JBwNnAG8E5gOflzRlx8qPiIiJGFfoS5oNnARcUtYFHANcWbqsABaW5QVlnbL92NJ/AXC57ads/xgYBA7vxk5ERMT4jPdI//8Cvwf8rKy/Cvip7WfL+gZgVlmeBTwAULZvLf1/3j7Cc35O0hJJayWt3bx58wR2JSIixjJm6Es6Gdhke10P6sH2MtsDtgdmzJjRi7eMiKjG1HH0OQo4RdKJwCuAvYHPAdMkTS1H87OBjaX/RmAOsEHSVGAf4JGO9mGdz4mIiB4Y80jf9sdsz7a9P82J2O/Yfg/wXeDU0m0RcFVZXlXWKdu/Y9ul/Ywyu+cAYC5wY9f2JCIixjSeI/3RnANcLumTwI+AS0v7pcBXJA0CQzQfFNi+XdJK4A7gWeBs28/twPtHRMQETSj0bX8P+F5ZvpcRZt/YfhI4bZTnfwr41ESLjIiI7sgVuRERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUZMzQl/QKSTdK+n+Sbpf0h6X9AEk3SBqUdIWk3Ur77mV9sGzfv+O1Plba75Z0/GTtVEREjGw8R/pPAcfYfgtwCDBf0pHAp4ELbb8B2AIsLv0XA1tK+4WlH5IOBs4A3gjMBz4vaUo3dyYiIrZvzNB349/K6svLj4FjgCtL+wpgYVleUNYp24+VpNJ+ue2nbP8YGAQO78peRETEuIxrTF/SFEm3AJuA1cA9wE9tP1u6bABmleVZwAMAZftW4FWd7SM8p/O9lkhaK2nt5s2bJ75HERExqnGFvu3nbB8CzKY5Oj9osgqyvcz2gO2BGTNmTNbbRERUaUKzd2z/FPgu8CvANElTy6bZwMayvBGYA1C27wM80tk+wnMiIqIHxjN7Z4akaWV5D+A44E6a8D+1dFsEXFWWV5V1yvbv2HZpP6PM7jkAmAvc2K0diYiIsU0duwv7ASvKTJuXASttXy3pDuBySZ8EfgRcWvpfCnxF0iAwRDNjB9u3S1oJ3AE8C5xt+7nu7k5ERGzPmKFv+1bg0BHa72WE2Te2nwROG+W1PgV8auJlRkREN4znSD+ip/Zfek1P3+++C07q6ftFtCm3YYiIqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIrm1ckSP5dbR0aYc6UdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkTFDX9IcSd+VdIek2yV9pLTvK2m1pPXlcXppl6SLJA1KulXSYR2vtaj0Xy9p0eTtVkREjGQ8R/rPAr9r+2DgSOBsSQcDS4E1tucCa8o6wAnA3PKzBLgYmg8J4FzgCOBw4NzhD4qIiOiNMUPf9oO2by7LjwF3ArOABcCK0m0FsLAsLwAuc+N6YJqk/YDjgdW2h2xvAVYD87u6NxERsV0TGtOXtD9wKHADMNP2g2XTQ8DMsjwLeKDjaRtK22jt277HEklrJa3dvHnzRMqLiIgxjDv0Jf0C8FfAR20/2rnNtgF3oyDby2wP2B6YMWNGN14yIiKKcYW+pJfTBP5Xbf91aX64DNtQHjeV9o3AnI6nzy5to7VHRESPjGf2joBLgTttf7Zj0ypgeAbOIuCqjvYzyyyeI4GtZRjoOmCepOnlBO680hYRET0ynrtsHgW8D7hN0i2l7ePABcBKSYuB+4HTy7ZrgROBQeAJ4CwA20OSzgduKv3Osz3Ulb2IiIhxGTP0bX8f0Cibjx2hv4GzR3mt5cDyiRQYERHdkytyIyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqki9Gj4iuyZe+7/xypB8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGEfkRERRL6EREVSehHRFRkzNCXtFzSJkn/3NG2r6TVktaXx+mlXZIukjQo6VZJh3U8Z1Hpv17SosnZnYiI2J7xHOl/GZi/TdtSYI3tucCasg5wAjC3/CwBLobmQwI4FzgCOBw4d/iDIiIiemfM0Lf9D8DQNs0LgBVleQWwsKP9MjeuB6ZJ2g84Hlhte8j2FmA1L/4giYiISfZSx/Rn2n6wLD8EzCzLs4AHOvptKG2jtb+IpCWS1kpau3nz5pdYXkREjGSHT+TaNuAu1DL8estsD9gemDFjRrdeNiIieOmh/3AZtqE8birtG4E5Hf1ml7bR2iMioodeauivAoZn4CwCrupoP7PM4jkS2FqGga4D5kmaXk7gzittERHRQ1PH6iDp68DbgFdL2kAzC+cCYKWkxcD9wOml+7XAicAg8ARwFoDtIUnnAzeVfufZ3vbkcERETLIxQ9/2u0fZdOwIfQ2cPcrrLAeWT6i6iIjoqlyRGxFRkYR+RERFEvoRERUZc0w/IiIa+y+9pqfvd98FJ3X9NXOkHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFeh76kuZLulvSoKSlvX7/iIia9TT0JU0B/hw4ATgYeLekg3tZQ0REzXp9pH84MGj7XttPA5cDC3pcQ0REtWS7d28mnQrMt/3+sv4+4AjbH+zoswRYUlYPBO7uWYHwauAnPXy/Xsv+7dr6ef/6ed+g9/v3WtszRtowtYdFjIvtZcCyNt5b0lrbA228dy9k/3Zt/bx//bxvsHPtX6+HdzYCczrWZ5e2iIjogV6H/k3AXEkHSNoNOANY1eMaIiKq1dPhHdvPSvogcB0wBVhu+/Ze1jCGVoaVeij7t2vr5/3r532DnWj/enoiNyIi2pUrciMiKpLQj4ioSEI/IqIiVYe+pHdIqvq/wa5KjTlj94yITrUH3m8A6yX9saSD2i5mskmaLunNbdfRDW5mIFzbdh2TRdIUSXe1Xcdkk/RaSb9WlveQtFfbNXWLpJmSLpX0zbJ+sKTFbddVdejbfi9wKHAP8GVJ/yRpSZ/94n1P0t6S9gVuBr4o6bNt19UlN0v65baLmAy2nwPulvRLbdcyWST9FnAl8IXSNBv4m/Yq6rov00xPf01Z/xfgo61VU1Qd+gC2H6X5xbsc2A94J02YfKjVwrpnn7KPvw5cZvsI4NdarqlbjgD+SdI9km6VdJukW9suqoumA7dLWiNp1fBP20V10dnAUcCjALbXA7/YakXd9WrbK4GfQXOdEvBcuyXthPfe6SVJpwBnAW8ALgMOt71J0iuBO4A/bbO+LpkqaT/gdOB/tV1Mlx3fdgGT7BNtFzDJnrL9tCQAJE0F+unCocclvYqyT5KOBLa2W1LloQ+8C7jQ9j90Ntp+YmcYe+uS82j+xPy+7ZskvQ5Y33JNXWH7fklHA3Ntf0nSDOAX2q6rW2z/fds1TLK/l/RxYA9JxwH/Hfjblmvqpt+huc3M6yX9AJgBnNpuSbkiF0kzgeFx4Rttb2qznhg/SecCA8CBtv+DpNcAf2n7qJZL64pyZPinwH8EdqO5dcnjtvdutbAuKTPnFgPzANEcnFziPgql8tfLgTT7d7ftZ1ouqe4xfUmnATcCp9EMf9xQ7vnfN8rMpL0lvbyMDW+W9N626+qSdwKnAI8D2P5XoG9OwgN/Bryb5i+zPYD303zzXL9YSHOe6TTbp9r+Yp8F/mnAHuX+YguBKyQd1nJZdYc+8PvAL9teZPtMmm/26rdx1HnlRO7JwH005y/+Z6sVdc/TJSSGx0z3bLmerrM9CEyx/ZztLwHz266pi94B/Iukr0g6uRwV95NP2H6sDEEeC1wKXNxyTdWH/su2Gc55hP77bzL8D+kkmqGP1k8kddFKSV8AppXpf38HfLHlmrrpiXIL8lvKX2y/TR/9ftoenkTxlzR/0dwj6ZJ2q+qq4Zk6JwFftH0NzTBdq/rtk3WiviXpOuDrZf0M4Jst1jMZri4X+fw78IFysvPJlmvqCtt/Uk4APkozbvoHtle3XFY3vY8m5D8I/DbNFxC9q9WKusz2M+XiJdMMYS2kGcbqBxvLQclxwKcl7c5O8KGdE7nSr9PMFQb4R9v9dHEIAOXCrK22nytDIHvZfqjtumJskvYAfsl2L78ruicknUBzVfzbgO8BK4Fvl/nsu7wy9Xs+cJvt9WXq9Jtsf7vVumoMfUnft320pMdojjDUsflnwBDwGdufb6XALiq/eL9DExxLJM2lme1ydcul7bCO/3+dtgJrgd+1fW/vq+oeSe8A/gTYzfYBkg4BzrN9SsuldYWkrwNXAN+0/VTb9XSLpL1tP1oOtl7E9lCva+pUZeiPpVxQ8UPbB7Zdy46SdAWwDjjT9n8qHwI/tH1Iy6XtMEnnAxuAr9F8cJ8BvJ7mdhMfsP229qrbcZLWAccA37N9aGm7zfab2q2se/pxyrSkq22fLOnHvPig0rZf11JpwE4wvrQzsv0IzZ+c/eD1tv8YeAaaC8944S/hruwU21+w/ZjtR20vA463fQXNLQx2dc+McOK9b47S+nXKdAl8Af/F9utsH9Dx02rgQ07kjsr2g23X0CVPl3Hh4WmNrwf65U/pJySdTnPvJGiudhw+Sd0P4Xi7pP8KTCnDch8GfthyTd00PGV6E0CZZPB3PP//c5dl25KuAXa6v8pypN//zgW+BcyR9FVgDfB77ZbUNe+hmeGyCXi4LL+3fMh9sM3CdoSkr5TFe4A30nxIf51mllLrd2nson6fMr1T3gU2Y/oVKOcojqQZ1rne9k9aLim2Q9IdNHdC/Sbw9m23t30isFskfQZ4M89Pmf4N4Fbb57RXVfeUqdJvAO6nuWpcNH8EtPqdFgn9CkiaBbyWjuG8bW8ytysqwwG/BezPC/ftN9uqqRskfRj4APA6YGPnJnaCE4HdJOldvHDK9DfarKebJL12pHbb9/e6lk4J/T4n6dM0R1C3U+7rTRMcu/y0P0k/BP6RZnbSz+9TbvuvWiuqiyRdbPsDbdcRL125187RNOeYfmD75pZLSuj3O0l3A2/up3nQwyTd0g9TT2szyvUV8PxfMv1yF9E/oJmZ9NelaSHNrVA+2V5VCf2+Vy5xP832v7VdS7dJ+iTNNQd9+125sesqB1xvsf1kWd8DuKXt638yZbP/PUFzw641dEzVtP3h9krqmo8AH5f0FM11CH11pBi7vH8FXsHz04h354XnaFqR0O9/q8pP37G9V7nUfS7NP66InclWmmstVtMMZx0H3CjpImjvwCvDO7HLkvR+mqP92cAtNNNSf2j72FYLiwAkLdredtsrelVLpxzp9ylJt7Gdq1LbnivcJR+huW/L9bbfLukg4I9arikCSVNovsDoPW3Xsq2Efv86uTyeXR6Hr/J8L/1xiwKAJ20/KQlJu9u+S9Iuf5O82PWV25i/VtJutp9uu55OCf0+NXwBiKTjhu/QWJwj6WZgaTuVddUGSdOAvwFWS9pCc/VjxM7gXuAHklZRvscZwPZn2yspoV8DSTrK9g/Kyq/SJ/c3sf3Osvi/JX0X2IfmPkMRO4N7ys/LgL1aruXnciK3z0l6K7CcJhAFbAF+c2e4MjAiei+hXwlJ+wD02RejR+y0yl+fLwpY28e0UM7PZXinApJOorlF7yua73YA2+e1WlRE//sfHcuvoPlS+9a//zeh3+ck/QXwSppb9F5C80UjN7ZaVEQFbK/bpukHklr/t5fQ73+/avvNkm61/YeS/g/NfdojYhJt88XoLwMGaM6ttSqh3/+G7/vxhKTXAEPAfi3WE1GLdTz/xejPAPcBi9ssCPpk6l5s19+WueyfAW4Gfgx8rd2SIqpwDnCI7QNoLo58nOYGiK1K6Pe/u4DnyheL/DlwPc3FTBExuX7f9qOSjgaOoTmndnHLNSX0K/AJ24/tbL94ERUY/ja3k4Av2r4G2K3FeoCEfg12yl+8iApslPQFmq8rvVbS7uwEmZuLs/qcpKtpvrjhOOAw4N+BG22/pdXCIvqcpFcC84HbbK+XtB/wJtvfbrWuhH5/21l/8SKiHQn9iIiKtD6+FBERvZPQj4ioSEI/IqIiCf2IiIr8f3bgzaJna+dKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Comaf36-Hb6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19808ffa-0e70-45c8-d922-847294af0586"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text        20000\n",
              "emotions    20000\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYxc8fx_H3ad"
      },
      "source": [
        "Data has been preprocessed already, using technique from this paper: https://www.aclweb.org/anthology/D18-1404/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYKK7ujRHfRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "6524d119-dafd-4904-bb76-95606df2db5a"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>137246</th>\n",
              "      <td>im really not sure how i feel about it because...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11150</th>\n",
              "      <td>i feel a little apprehensive about tomorrow</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13240</th>\n",
              "      <td>i can t stop the anxiety i feel when i m alone...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52074</th>\n",
              "      <td>im blogging because i feel overly stressed and...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88936</th>\n",
              "      <td>i should be over there making the most of it b...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "137246  im really not sure how i feel about it because...      joy\n",
              "11150         i feel a little apprehensive about tomorrow     fear\n",
              "13240   i can t stop the anxiety i feel when i m alone...  sadness\n",
              "52074   im blogging because i feel overly stressed and...    anger\n",
              "88936   i should be over there making the most of it b...  sadness"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXovcl56NFPp"
      },
      "source": [
        "## reset index\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSzoz9InH0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7caa75-bae2-4fcd-deb5-7f01fd27663a"
      },
      "source": [
        "## check unique emotions in the dataset\n",
        "data.emotions.unique()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['joy', 'fear', 'sadness', 'anger', 'love', 'surprise'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm31gKShQus"
      },
      "source": [
        "## Split the data and store into individual text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ooNxSnPiztL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "4699498d-b662-4967-8b48-93fb1a2d5b00"
      },
      "source": [
        "## uncomment the code below to generate the text files for your train, val, and test datasets.\n",
        "\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_train, input_val, target_train, target_val = train_test_split(data.text.to_numpy(), \n",
        "                                                                    data.emotions.to_numpy(), \n",
        "                                                                    test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_val, input_test, target_val, target_test = train_test_split(input_val, target_val, test_size=0.5)\n",
        "\n",
        "\n",
        "## create a dataframe for each dataset\n",
        "train_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": target_train})\n",
        "val_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": target_val})\n",
        "test_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": target_test})\n",
        "final_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\n",
        "\n",
        "train_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\n",
        "val_dataset.to_csv(test_path, sep=\";\",header=False, index=False)\n",
        "test_dataset.to_csv(val_path, sep=\";\",header=False, index=False)\n",
        "'''"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom sklearn.model_selection import train_test_split\\nimport numpy as np\\n\\n# Creating training and validation sets using an 80-20 split\\ninput_train, input_val, target_train, target_val = train_test_split(data.text.to_numpy(), \\n                                                                    data.emotions.to_numpy(), \\n                                                                    test_size=0.2)\\n\\n# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\\ninput_val, input_test, target_val, target_test = train_test_split(input_val, target_val, test_size=0.5)\\n\\n\\n## create a dataframe for each dataset\\ntrain_dataset = pd.DataFrame(data={\"text\": input_train, \"class\": target_train})\\nval_dataset = pd.DataFrame(data={\"text\": input_val, \"class\": target_val})\\ntest_dataset = pd.DataFrame(data={\"text\": input_test, \"class\": target_test})\\nfinal_dataset = {\"train\": train_dataset, \"val\": val_dataset , \"test\": test_dataset }\\n\\ntrain_dataset.to_csv(train_path, sep=\";\",header=False, index=False)\\nval_dataset.to_csv(test_path, sep=\";\",header=False, index=False)\\ntest_dataset.to_csv(val_path, sep=\";\",header=False, index=False)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAD1J6c0dLp8"
      },
      "source": [
        "## Create the Dataset object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOOI69vwIYcN"
      },
      "source": [
        "Create the Dataset object that will be used to load the different datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktr6xeMuISin"
      },
      "source": [
        "class EmoDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        super().__init__()\n",
        "        self.data_column = \"text\"\n",
        "        self.class_column = \"class\"\n",
        "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
        "                               engine=\"python\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EYQRq3qJH7n"
      },
      "source": [
        "Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGWw4wGEJGhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2f78f0-3916-4ddc-d6ed-4d0dd94e366e"
      },
      "source": [
        "ds = EmoDataset(train_path)\n",
        "ds[19]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('i now feel compromised and skeptical of the value of every unit of work i put in',\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h6tTn9hd6v8"
      },
      "source": [
        "## Training with PyTorchLightning\n",
        "\n",
        "PyTorchLightning is just a library that abstracts the complexity of training neural networks with PyTorch. It is built on top of PyTorch and simplifies training.\n",
        "\n",
        "![](https://pytorch-lightning.readthedocs.io/en/latest/_images/pt_to_pl.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJHhNRcZK7sV"
      },
      "source": [
        "## Methods required by PyTorchLightning\n",
        "\n",
        "class TrainingModule(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.model = EmoModel(AutoModelWithLMHead.from_pretrained(\"distilroberta-base\").base_model, len(emotions))\n",
        "        self.loss = nn.CrossEntropyLoss() ## combines LogSoftmax() and NLLLoss()\n",
        "        for key, value in vars(hparams).items():\n",
        "          self.hparams[key]=value\n",
        "        #self.hparams = hparams\n",
        "\n",
        "    def step(self, batch, step_name=\"train\"):\n",
        "        X, y = batch\n",
        "        loss = self.loss(self.forward(X), y)\n",
        "        loss_key = f\"{step_name}_loss\"\n",
        "        tensorboard_logs = {loss_key: loss}\n",
        "\n",
        "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
        "               \"progress_bar\": {loss_key: loss}}\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        return self.model(X, *args)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, \"train\")\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, \"val\")\n",
        "\n",
        "    def validation_end(self, outputs: List[dict]):\n",
        "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        return {\"val_loss\": loss}\n",
        "        \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.step(batch, \"test\")\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.create_data_loader(self.hparams.val_path)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.create_data_loader(self.hparams.test_path)\n",
        "                \n",
        "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
        "        return DataLoader(\n",
        "                    EmoDataset(ds_path),\n",
        "                    batch_size=self.hparams.batch_size,\n",
        "                    shuffle=shuffle,\n",
        "                    collate_fn=TokenizersCollateFn()\n",
        "        )\n",
        "        \n",
        "    @lru_cache()\n",
        "    def total_steps(self):\n",
        "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        ## use AdamW optimizer -- faster approach to training NNs\n",
        "        ## read: https://www.fast.ai/2018/07/02/adam-weight-decay/\n",
        "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr)\n",
        "        lr_scheduler = get_linear_schedule_with_warmup(\n",
        "                    optimizer,\n",
        "                    num_warmup_steps=self.hparams.warmup_steps,\n",
        "                    num_training_steps=self.total_steps(),\n",
        "        )\n",
        "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGc7Vw1moHxr"
      },
      "source": [
        "## Finding Learning rate for the model\n",
        "\n",
        "The code below aims to obtain valuable information about the optimal learning rate during a pretraining run. Determine boundary and increase the leanring rate linearly or exponentially.\n",
        "\n",
        "More: https://github.com/davidtvs/pytorch-lr-finder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL4lNPDFoFyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b5e588-b7f3-47c3-bdf3-387595d55d3e"
      },
      "source": [
        "!pip install torch-lr-finder\n",
        "lr=0.1 ## uper bound LR\n",
        "# from torch_lr_finder import LRFinder\n",
        "# hparams_tmp = Namespace(\n",
        "#     train_path=train_path,\n",
        "#     val_path=val_path,\n",
        "#     test_path=test_path,\n",
        "#     batch_size=16,\n",
        "#     warmup_steps=100,\n",
        "#     epochs=1,\n",
        "#     lr=lr,\n",
        "#     accumulate_grad_batches=1,\n",
        "# )\n",
        "# module = TrainingModule(hparams_tmp)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = AdamW(module.parameters(), lr=5e-7) ## lower bound LR\n",
        "# lr_finder = LRFinder(module, optimizer, criterion, device=\"cuda\")\n",
        "# lr_finder.range_test(module.train_dataloader(), end_lr=100, num_iter=100, accumulation_steps=hparams_tmp.accumulate_grad_batches)\n",
        "# lr_finder.plot()\n",
        "# lr_finder.reset()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.9.0+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdqP56M1oXav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1944f587-0f53-4a4f-f059-d41d92de88fe"
      },
      "source": [
        "lr = 1e-4 \n",
        "lr"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMab6vu0Bow0"
      },
      "source": [
        "# lr_finder.plot(show_lr=lr)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhHutCseBxjJ"
      },
      "source": [
        "## Training the Emotion Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3FiLr3LBrjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789c9250-badc-4b03-a619-7553b4db0063"
      },
      "source": [
        "hparams = Namespace(\n",
        "    train_path=train_path,\n",
        "    val_path=val_path,\n",
        "    test_path=test_path,\n",
        "    batch_size=32,\n",
        "    warmup_steps=100,\n",
        "    epochs=1,\n",
        "    lr=lr,\n",
        "    accumulate_grad_batches=1\n",
        ")\n",
        "\n",
        "module = TrainingModule(hparams)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Jv_U25B37g"
      },
      "source": [
        "## garbage collection\n",
        "import gc; gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRnl4HXvB5-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "9f974fd93f0548879967ad9fe26a7995",
            "595e5f50bdb14e00835027cfd6dccadf",
            "4a7336b4a47e4f2f80ea1e6e11b49c3a",
            "791559c84a8f43b69f9cffecf07c82ec",
            "c3a06e98ceb545f8ad955726dd5fedb5",
            "eafce52682004ac88f1ba5720547e30a",
            "5cf48fbb01404856870e44d259480ba2",
            "d85cde11b72c47fcbd4b0f981ebd7509",
            "1dcb65c8229f4c68b91d92cd11ab69ee",
            "05849f652a2744b888d8e0fb0766b130",
            "bdff77833c7e40a694ca7eed04f6742b",
            "62db80574db247bdbb2bb349bfbd4313",
            "cb0876485bd14222bd59438a02d480ad",
            "aaed7774dcd94b79b7fd67504b2407fe",
            "297c91a785fe4627a510819f11993a3b",
            "76dedd8c338a48eeb57177356c4b39be",
            "433e95fb096d4cf18cb33119ca65739e",
            "8dde433a7293480ba25760099224740c",
            "4888f700b50d4668bcfde24fc863c850",
            "3d0a46794481436fb3ff8447a99c4c73",
            "0f73ebf79e064c72a155437db7376180",
            "4240775062764e1981a1ac7ebc16fd92",
            "9f315c9bcdab41cc8d2607ce61dc24d9",
            "366f8596c92c4c7f81b3945e0ea4dc8c",
            "b28a5eaeef9c4f4bbbcbc091328c0454",
            "9f912b99c72140b0bc4c24367cc4ccc4",
            "d289240c3e124718a7e2c481b553a167",
            "a834799c634344b59538b594ed22179a",
            "78b85a16bc6c441083c3d223c5eb1a29",
            "d55d5eb488d0408f95ec741ed6d3b896",
            "e5e408da51574829add47a99cbceba65",
            "0f5843b51ef644efaa6d86d6cec2af5e",
            "420c8b69731d4e309f0547a3e92758f1"
          ]
        },
        "outputId": "cd051ce3-f3ff-42d8-ff28-f5bbad8b04ad"
      },
      "source": [
        "## train roughly for about 10-15 minutes with GPU enabled.\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
        "                     accumulate_grad_batches=hparams.accumulate_grad_batches)\n",
        "\n",
        "trainer.fit(module)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=10)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type             | Params\n",
            "-------------------------------------------\n",
            "0 | model | EmoModel         | 82.1 M\n",
            "1 | loss  | CrossEntropyLoss | 0     \n",
            "-------------------------------------------\n",
            "82.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "82.1 M    Total params\n",
            "328.492   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f974fd93f0548879967ad9fe26a7995",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62db80574db247bdbb2bb349bfbd4313",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/closure.py:36: LightningDeprecationWarning: One of the returned values {'log', 'progress_bar'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
            "  f\"One of the returned values {set(extra.keys())} has a `grad_fn`. We will detach it automatically\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f315c9bcdab41cc8d2607ce61dc24d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SzjqDBDbECS"
      },
      "source": [
        "device = 'cuda'\n",
        "module.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8kzE1AeB_ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3572d001-c74c-43f8-d38f-b86eba5abc2a"
      },
      "source": [
        "with torch.no_grad():\n",
        "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
        "    module.eval()\n",
        "    true_y, pred_y = [], []\n",
        "    for i, batch_ in enumerate(module.test_dataloader()):\n",
        "        (X, attn), y = batch_\n",
        "        batch = (X.cuda(), attn.cuda())\n",
        "        print(progress[i % len(progress)], end=\"\\r\")\n",
        "        y_pred = torch.argmax(module(batch), dim=1)\n",
        "        true_y.extend(y.cpu())\n",
        "        pred_y.extend(y_pred.cpu())\n",
        "print(\"\\n\" + \"_\" * 80)\n",
        "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=len(emotions)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "________________________________________________________________________________\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     sadness   0.966783  0.951807  0.959237       581\n",
            "         joy   0.964018  0.925180  0.944200       695\n",
            "        love   0.782609  0.905660  0.839650       159\n",
            "       anger   0.920863  0.930909  0.925859       275\n",
            "        fear   0.908654  0.843750  0.875000       224\n",
            "    surprise   0.681319  0.939394  0.789809        66\n",
            "\n",
            "    accuracy                       0.923500      2000\n",
            "   macro avg   0.870708  0.916117  0.888959      2000\n",
            "weighted avg   0.928936  0.923500  0.924889      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0_Z_4Pkl3fc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}