{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in all data\n",
    "test = pd.read_csv('../data/test.txt', delimiter=';', names=['text', 'target'])\n",
    "train = pd.read_csv('../data/train.txt', delimiter=';',\n",
    "                    names=['text', 'target'])\n",
    "val = pd.read_csv('../data/val.txt', delimiter=';', names=['text', 'target'])\n",
    "trainval = pd.concat([train,val])\n",
    "testval = pd.concat([test,val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Either one of corpus_file or corpus_iterable value must be provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a86dca91f137>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dstum\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         self.add_lifecycle_event(\n",
      "\u001b[1;32mC:\\Users\\dstum\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_check_corpus_sanity\u001b[1;34m(self, corpus_iterable, corpus_file, passes)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         \u001b[1;34m\"\"\"Checks whether the corpus parameters make sense.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1493\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Either one of corpus_file or corpus_iterable value must be provided\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Both corpus_file and corpus_iterable must not be provided at the same time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Either one of corpus_file or corpus_iterable value must be provided"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "w2v = gensim.models.word2vec.Word2Vec(trainval.text)\n",
    "w2v.train(total_examples=w2v.corpus_count, epochs=2, corpus_iterable=True)\n",
    "\n",
    "w2v.wv[trainval.text[100]]\n",
    "#print('Number of Features: ',len(vectorizer.get_feature_names()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classification with DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "bag = BaggingClassifier(n_estimators=10, random_state=0)\n",
    "bag.fit(X_train, Y_train)\n",
    "Y_test_pred = bag.predict(X_test)\n",
    "\n",
    "train_acc = bag.score(X_train, Y_train)\n",
    "test_acc = bag.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics\n",
    "\n",
    "print('---------------- Bagging Statistics ----------------')\n",
    "print('Train Accuracy: {:.4}'.format(train_acc))\n",
    "print('Test Accuracy: {:.4}'.format(test_acc))\n",
    "print(skm.classification_report(Y_test, Y_test_pred))\n",
    "pd.DataFrame(skm.confusion_matrix(Y_test, Y_test_pred), \n",
    "    columns=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'],\n",
    "             index=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "rf.fit(X_train, Y_train)\n",
    "Y_test_pred = rf.predict(X_test)\n",
    "\n",
    "train_acc = rf.score(X_train, Y_train)\n",
    "test_acc = rf.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Random Forest Statistics -------------')\n",
    "print('Train Accuracy: {:.4}'.format(train_acc))\n",
    "print('Test Accuracy: {:.4}'.format(test_acc))\n",
    "print(skm.classification_report(Y_test, Y_test_pred))\n",
    "pd.DataFrame(skm.confusion_matrix(Y_test, Y_test_pred),\n",
    "             columns=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'],\n",
    "             index=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classification with DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada.fit(X_train, Y_train)\n",
    "Y_test_pred = ada.predict(X_test)\n",
    "\n",
    "train_acc = ada.score(X_train, Y_train)\n",
    "test_acc = ada.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('---------------- AdaBoost Statistics ----------------')\n",
    "print('Train Accuracy: {:.4}'.format(train_acc))\n",
    "print('Test Accuracy: {:.4}'.format(test_acc))\n",
    "print(skm.classification_report(Y_test, Y_test_pred))\n",
    "pd.DataFrame(skm.confusion_matrix(Y_test, Y_test_pred),\n",
    "             columns=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'],\n",
    "             index=['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ccb67de7081a05f54dc297e18d4107ab1f61dedc55f288c5f31e7d83840b6d4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
